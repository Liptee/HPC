Общее
=====

В данном репозитории находится файл README.md, основной файл
MatrixMultipliccation и дополнительный файл TPBmore32 с расширением ipynb.
Лабараторная работа выполнялась в Google Colaboratory на языке Python с помощью
таких библиотек как:

-   numba

-   numpy

-   matplotlib

-   math

-   datetime

О MatrixMultiplication.ipynb
============================

Первый блок
-----------

Данный файл разделен на два блока кода. В первом блоке происходит умножение
матриц в цикле для CPU и для GPU и сохранение значений размера матрицы и
скорости выполнения в массивы для дальнейшего использования. Цикл использует
аргумент TBS, который в самом коде отвечает за размер матрицы и размер
виртуального блока потоков. Данное решение принято для более быстрого вычисления
через GPU. Цикл начинается со значения TBS равному 1, то есть он умножает
матрицу размером 1 на 1, используя в одном блоке 1 поток. Функцию с данным
значением TBS код выполняет три раза, и затем повышает значение TBS на 1, и
далее идет вычисление матриц размером 2х2, используя в одном блоке 4 потока
также размером 2х2 и так далее, пока не прервать выполнение кода или же код
полностью не выполнится с максимальным аргументом TBS равному 32, так как вы не
рекомендовали указывать в блоке количество потоков более 1024 (второй файл
посвящен проверке этой рекомендации).

 

Также после каждого цикла результаты умножения матриц CPU и GPU сравниваются
между собой, данным способом:

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 ch = True
  res = CPU_res - GPU_res
  for row in res:
    for el in row:
      if el != 0:
        ch = False
        break
  if ch:
    print('Matricies are equal')
  else:
    print ('error')
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Матрицы вычитаются друг из друга, что при их индентичности должно давать ноль,
для каждого значения матрицы. Результат вычитания проверяется на наличия “не
нулей” и если они отсутсвуют, то значит исходные матрицы равны.

 

Далее следует вызов уже самой основной функции “info” и цикл while для TBS.

 

 

Второй блок
-----------

Второй блок визуализирует полученные из первого блока массивы данных, и
сравнивает зависимость выполнения операции от размера матрицы для CPU и GPU.
Поскольку выполнение первого блока кода занимает довольно много времени, то его
выполнение можно прервать и посмотреть на полученные результаты во втором блоке.

 

О TPBmore32.ipynb
=================

Ради интереса, я решил посмотреть, как будет выполняться вычисления на GPU, если
превысить размер блока потоков 32х32. Данный файл для вычислений использует
только GPU и производит вычисления исправно, пока переменная TBS не будет равна
33, тогда при передаче функции размера блока потоков код выдает ошибку:

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 MatMul_cuda[blockgrid, block](d_A, d_B, d_C) # Строка с передачей функции ее атрибутов

CudaAPIError: [1] Call to cuLaunchKernel results in CUDA_ERROR_INVALID_VALUE 
# Ошибка 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Мой интерес был удовлетворен.

 

Итоги
=====

Если смотреть на таблицу сравнения результатов скорости вычислений GPU и CPU, то
видно, что кривая зависимости вычислений на CPU от размера матрицы представляет
собой параболлу параллельно оси x, напоминающую функцию **y** равного **корень**
из **x**. А вычисления на GPU представляют собой почти вертикальную линию,
параллельную оси **y**, с минимальным влиянием размера матрицы на время
вычисления. При небольших размерах матрицы CPU справляется с задачей быстрее,
полагаю из-за более высокой герцовки ядер процессора. Хотя, конечно все зависит
от конфигурации. Я запускал этот код также локально на машине с GPU NVIDIA
GeForce GTX 970 и Intel Core i7 пятого поколения и помимо того, что вычисления,
что на CPU и на GPU проходили быстрее, чем на предоставляемой Google
конфигурации , GPU заметно раньше начала обгонять CPU в скорости вычисления.

 
