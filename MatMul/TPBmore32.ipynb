{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPBmore32.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wMiwivme3a-j",
        "outputId": "87c6fcfe-349e-4887-b28b-88e59b4b4bd1"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from numba import cuda, jit\n",
        "from datetime import datetime\n",
        "\n",
        "CPU_tmp = 0 \n",
        "GPU_tmp = 0 \n",
        "GPU_time = []\n",
        "GPU_matsize = []\n",
        "\n",
        "def info(TBS): \n",
        "  A = np.random.uniform (-100, 100, TBS*TBS*TBS*TBS)\n",
        "  A = A.reshape(TBS*TBS, TBS*TBS)\n",
        "  B = np.random.uniform (-100, 100, TBS*TBS*TBS*TBS)\n",
        "  B = B.reshape(TBS*TBS, TBS*TBS)\n",
        "  C = np.zeros((TBS*TBS,TBS*TBS ))\n",
        "\n",
        "  @cuda.jit \n",
        "  def MatMul_cuda(A, B, C):\n",
        "    i, j = cuda.grid(2)\n",
        "    if i < C.shape[0] and j < C.shape[1]:\n",
        "      sum = 0\n",
        "      for k in range(A.shape[1]):\n",
        "        sum += A[i, k] * B[k, j]\n",
        "        C[i, j] = sum\n",
        "\n",
        "      \n",
        "  def host_naive(A,B,C): \n",
        "    d_A = cuda.to_device(A) \n",
        "    d_B = cuda.to_device(B)\n",
        "    d_C = cuda.device_array(C.shape, np.float64)\n",
        "\n",
        "    block = (TBS, TBS)\n",
        "    blockgrid_x = math.ceil(A.shape[0]/ block[0])\n",
        "    blockgrid_y = math.ceil(B.shape[1]/ block[1])\n",
        "    blockgrid = (blockgrid_x, blockgrid_y)\n",
        "    print(block)\n",
        "    \n",
        "\n",
        "    MatMul_cuda[blockgrid, block](d_A, d_B, d_C)\n",
        "\n",
        "    return d_C.copy_to_host()\n",
        "\n",
        "  start = datetime.now()\n",
        "  host_naive(A,B,C)\n",
        "  GPU_res = C\n",
        "  print(\"GPU MatMul's time: \", datetime.now() - start)\n",
        "  GPU_tmp=(datetime.now()-start)\n",
        "  GPU_time.append(GPU_tmp.total_seconds())\n",
        "  GPU_matsize.append(TBS*TBS*TBS*TBS)\n",
        "\n",
        "TBS = 0\n",
        "while TBS <=64:\n",
        "  count = 1\n",
        "  print()\n",
        "  print(\"TBS\", TBS)\n",
        "  TBS +=1\n",
        "  while count <=3:\n",
        "    print(\"Cycle\", count)\n",
        "    info(TBS)\n",
        "    count +=1\n",
        "print (\"Max size for TPB is 32!\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TBS 0\n",
            "Cycle 1\n",
            "(1, 1)\n",
            "GPU MatMul's time:  0:00:00.333506\n",
            "Cycle 2\n",
            "(1, 1)\n",
            "GPU MatMul's time:  0:00:00.246452\n",
            "Cycle 3\n",
            "(1, 1)\n",
            "GPU MatMul's time:  0:00:00.240610\n",
            "\n",
            "TBS 1\n",
            "Cycle 1\n",
            "(2, 2)\n",
            "GPU MatMul's time:  0:00:00.237090\n",
            "Cycle 2\n",
            "(2, 2)\n",
            "GPU MatMul's time:  0:00:00.240304\n",
            "Cycle 3\n",
            "(2, 2)\n",
            "GPU MatMul's time:  0:00:00.250619\n",
            "\n",
            "TBS 2\n",
            "Cycle 1\n",
            "(3, 3)\n",
            "GPU MatMul's time:  0:00:00.229944\n",
            "Cycle 2\n",
            "(3, 3)\n",
            "GPU MatMul's time:  0:00:00.232396\n",
            "Cycle 3\n",
            "(3, 3)\n",
            "GPU MatMul's time:  0:00:00.233959\n",
            "\n",
            "TBS 3\n",
            "Cycle 1\n",
            "(4, 4)\n",
            "GPU MatMul's time:  0:00:00.237569\n",
            "Cycle 2\n",
            "(4, 4)\n",
            "GPU MatMul's time:  0:00:00.236889\n",
            "Cycle 3\n",
            "(4, 4)\n",
            "GPU MatMul's time:  0:00:00.231067\n",
            "\n",
            "TBS 4\n",
            "Cycle 1\n",
            "(5, 5)\n",
            "GPU MatMul's time:  0:00:00.233932\n",
            "Cycle 2\n",
            "(5, 5)\n",
            "GPU MatMul's time:  0:00:00.332066\n",
            "Cycle 3\n",
            "(5, 5)\n",
            "GPU MatMul's time:  0:00:00.228403\n",
            "\n",
            "TBS 5\n",
            "Cycle 1\n",
            "(6, 6)\n",
            "GPU MatMul's time:  0:00:00.233548\n",
            "Cycle 2\n",
            "(6, 6)\n",
            "GPU MatMul's time:  0:00:00.233999\n",
            "Cycle 3\n",
            "(6, 6)\n",
            "GPU MatMul's time:  0:00:00.237086\n",
            "\n",
            "TBS 6\n",
            "Cycle 1\n",
            "(7, 7)\n",
            "GPU MatMul's time:  0:00:00.231527\n",
            "Cycle 2\n",
            "(7, 7)\n",
            "GPU MatMul's time:  0:00:00.228302\n",
            "Cycle 3\n",
            "(7, 7)\n",
            "GPU MatMul's time:  0:00:00.233268\n",
            "\n",
            "TBS 7\n",
            "Cycle 1\n",
            "(8, 8)\n",
            "GPU MatMul's time:  0:00:00.237909\n",
            "Cycle 2\n",
            "(8, 8)\n",
            "GPU MatMul's time:  0:00:00.244250\n",
            "Cycle 3\n",
            "(8, 8)\n",
            "GPU MatMul's time:  0:00:00.246343\n",
            "\n",
            "TBS 8\n",
            "Cycle 1\n",
            "(9, 9)\n",
            "GPU MatMul's time:  0:00:00.247340\n",
            "Cycle 2\n",
            "(9, 9)\n",
            "GPU MatMul's time:  0:00:00.240168\n",
            "Cycle 3\n",
            "(9, 9)\n",
            "GPU MatMul's time:  0:00:00.239641\n",
            "\n",
            "TBS 9\n",
            "Cycle 1\n",
            "(10, 10)\n",
            "GPU MatMul's time:  0:00:00.334529\n",
            "Cycle 2\n",
            "(10, 10)\n",
            "GPU MatMul's time:  0:00:00.229352\n",
            "Cycle 3\n",
            "(10, 10)\n",
            "GPU MatMul's time:  0:00:00.228643\n",
            "\n",
            "TBS 10\n",
            "Cycle 1\n",
            "(11, 11)\n",
            "GPU MatMul's time:  0:00:00.256616\n",
            "Cycle 2\n",
            "(11, 11)\n",
            "GPU MatMul's time:  0:00:00.231912\n",
            "Cycle 3\n",
            "(11, 11)\n",
            "GPU MatMul's time:  0:00:00.233830\n",
            "\n",
            "TBS 11\n",
            "Cycle 1\n",
            "(12, 12)\n",
            "GPU MatMul's time:  0:00:00.246416\n",
            "Cycle 2\n",
            "(12, 12)\n",
            "GPU MatMul's time:  0:00:00.240970\n",
            "Cycle 3\n",
            "(12, 12)\n",
            "GPU MatMul's time:  0:00:00.230334\n",
            "\n",
            "TBS 12\n",
            "Cycle 1\n",
            "(13, 13)\n",
            "GPU MatMul's time:  0:00:00.233367\n",
            "Cycle 2\n",
            "(13, 13)\n",
            "GPU MatMul's time:  0:00:00.230066\n",
            "Cycle 3\n",
            "(13, 13)\n",
            "GPU MatMul's time:  0:00:00.241487\n",
            "\n",
            "TBS 13\n",
            "Cycle 1\n",
            "(14, 14)\n",
            "GPU MatMul's time:  0:00:00.231959\n",
            "Cycle 2\n",
            "(14, 14)\n",
            "GPU MatMul's time:  0:00:00.228145\n",
            "Cycle 3\n",
            "(14, 14)\n",
            "GPU MatMul's time:  0:00:00.326909\n",
            "\n",
            "TBS 14\n",
            "Cycle 1\n",
            "(15, 15)\n",
            "GPU MatMul's time:  0:00:00.242888\n",
            "Cycle 2\n",
            "(15, 15)\n",
            "GPU MatMul's time:  0:00:00.231200\n",
            "Cycle 3\n",
            "(15, 15)\n",
            "GPU MatMul's time:  0:00:00.241162\n",
            "\n",
            "TBS 15\n",
            "Cycle 1\n",
            "(16, 16)\n",
            "GPU MatMul's time:  0:00:00.230437\n",
            "Cycle 2\n",
            "(16, 16)\n",
            "GPU MatMul's time:  0:00:00.236647\n",
            "Cycle 3\n",
            "(16, 16)\n",
            "GPU MatMul's time:  0:00:00.231622\n",
            "\n",
            "TBS 16\n",
            "Cycle 1\n",
            "(17, 17)\n",
            "GPU MatMul's time:  0:00:00.236314\n",
            "Cycle 2\n",
            "(17, 17)\n",
            "GPU MatMul's time:  0:00:00.232513\n",
            "Cycle 3\n",
            "(17, 17)\n",
            "GPU MatMul's time:  0:00:00.240076\n",
            "\n",
            "TBS 17\n",
            "Cycle 1\n",
            "(18, 18)\n",
            "GPU MatMul's time:  0:00:00.239364\n",
            "Cycle 2\n",
            "(18, 18)\n",
            "GPU MatMul's time:  0:00:00.237403\n",
            "Cycle 3\n",
            "(18, 18)\n",
            "GPU MatMul's time:  0:00:00.237067\n",
            "\n",
            "TBS 18\n",
            "Cycle 1\n",
            "(19, 19)\n",
            "GPU MatMul's time:  0:00:00.247363\n",
            "Cycle 2\n",
            "(19, 19)\n",
            "GPU MatMul's time:  0:00:00.259882\n",
            "Cycle 3\n",
            "(19, 19)\n",
            "GPU MatMul's time:  0:00:00.344807\n",
            "\n",
            "TBS 19\n",
            "Cycle 1\n",
            "(20, 20)\n",
            "GPU MatMul's time:  0:00:00.254421\n",
            "Cycle 2\n",
            "(20, 20)\n",
            "GPU MatMul's time:  0:00:00.255645\n",
            "Cycle 3\n",
            "(20, 20)\n",
            "GPU MatMul's time:  0:00:00.246933\n",
            "\n",
            "TBS 20\n",
            "Cycle 1\n",
            "(21, 21)\n",
            "GPU MatMul's time:  0:00:00.261095\n",
            "Cycle 2\n",
            "(21, 21)\n",
            "GPU MatMul's time:  0:00:00.279055\n",
            "Cycle 3\n",
            "(21, 21)\n",
            "GPU MatMul's time:  0:00:00.282300\n",
            "\n",
            "TBS 21\n",
            "Cycle 1\n",
            "(22, 22)\n",
            "GPU MatMul's time:  0:00:00.276185\n",
            "Cycle 2\n",
            "(22, 22)\n",
            "GPU MatMul's time:  0:00:00.270736\n",
            "Cycle 3\n",
            "(22, 22)\n",
            "GPU MatMul's time:  0:00:00.271331\n",
            "\n",
            "TBS 22\n",
            "Cycle 1\n",
            "(23, 23)\n",
            "GPU MatMul's time:  0:00:00.293261\n",
            "Cycle 2\n",
            "(23, 23)\n",
            "GPU MatMul's time:  0:00:00.284908\n",
            "Cycle 3\n",
            "(23, 23)\n",
            "GPU MatMul's time:  0:00:00.288596\n",
            "\n",
            "TBS 23\n",
            "Cycle 1\n",
            "(24, 24)\n",
            "GPU MatMul's time:  0:00:00.403362\n",
            "Cycle 2\n",
            "(24, 24)\n",
            "GPU MatMul's time:  0:00:00.295574\n",
            "Cycle 3\n",
            "(24, 24)\n",
            "GPU MatMul's time:  0:00:00.311655\n",
            "\n",
            "TBS 24\n",
            "Cycle 1\n",
            "(25, 25)\n",
            "GPU MatMul's time:  0:00:00.328293\n",
            "Cycle 2\n",
            "(25, 25)\n",
            "GPU MatMul's time:  0:00:00.329113\n",
            "Cycle 3\n",
            "(25, 25)\n",
            "GPU MatMul's time:  0:00:00.318217\n",
            "\n",
            "TBS 25\n",
            "Cycle 1\n",
            "(26, 26)\n",
            "GPU MatMul's time:  0:00:00.361634\n",
            "Cycle 2\n",
            "(26, 26)\n",
            "GPU MatMul's time:  0:00:00.343040\n",
            "Cycle 3\n",
            "(26, 26)\n",
            "GPU MatMul's time:  0:00:00.341234\n",
            "\n",
            "TBS 26\n",
            "Cycle 1\n",
            "(27, 27)\n",
            "GPU MatMul's time:  0:00:00.354973\n",
            "Cycle 2\n",
            "(27, 27)\n",
            "GPU MatMul's time:  0:00:00.353267\n",
            "Cycle 3\n",
            "(27, 27)\n",
            "GPU MatMul's time:  0:00:00.360516\n",
            "\n",
            "TBS 27\n",
            "Cycle 1\n",
            "(28, 28)\n",
            "GPU MatMul's time:  0:00:00.372662\n",
            "Cycle 2\n",
            "(28, 28)\n",
            "GPU MatMul's time:  0:00:00.451098\n",
            "Cycle 3\n",
            "(28, 28)\n",
            "GPU MatMul's time:  0:00:00.364737\n",
            "\n",
            "TBS 28\n",
            "Cycle 1\n",
            "(29, 29)\n",
            "GPU MatMul's time:  0:00:00.398679\n",
            "Cycle 2\n",
            "(29, 29)\n",
            "GPU MatMul's time:  0:00:00.409886\n",
            "Cycle 3\n",
            "(29, 29)\n",
            "GPU MatMul's time:  0:00:00.394779\n",
            "\n",
            "TBS 29\n",
            "Cycle 1\n",
            "(30, 30)\n",
            "GPU MatMul's time:  0:00:00.447784\n",
            "Cycle 2\n",
            "(30, 30)\n",
            "GPU MatMul's time:  0:00:00.445427\n",
            "Cycle 3\n",
            "(30, 30)\n",
            "GPU MatMul's time:  0:00:00.449791\n",
            "\n",
            "TBS 30\n",
            "Cycle 1\n",
            "(31, 31)\n",
            "GPU MatMul's time:  0:00:00.501945\n",
            "Cycle 2\n",
            "(31, 31)\n",
            "GPU MatMul's time:  0:00:00.498127\n",
            "Cycle 3\n",
            "(31, 31)\n",
            "GPU MatMul's time:  0:00:00.494421\n",
            "\n",
            "TBS 31\n",
            "Cycle 1\n",
            "(32, 32)\n",
            "GPU MatMul's time:  0:00:00.561270\n",
            "Cycle 2\n",
            "(32, 32)\n",
            "GPU MatMul's time:  0:00:00.556260\n",
            "Cycle 3\n",
            "(32, 32)\n",
            "GPU MatMul's time:  0:00:00.668783\n",
            "\n",
            "TBS 32\n",
            "Cycle 1\n",
            "(33, 33)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CudaAPIError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCudaAPIError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-740f875ad02d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m<=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cycle\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTBS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Max size for TPB is 32!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-740f875ad02d>\u001b[0m in \u001b[0;36minfo\u001b[0;34m(TBS)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m   \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m   \u001b[0mhost_naive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m   \u001b[0mGPU_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GPU MatMul's time: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-740f875ad02d>\u001b[0m in \u001b[0;36mhost_naive\u001b[0;34m(A, B, C)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mMatMul_cuda\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblockgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_C\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0md_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_to_host\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         return self.dispatcher.call(args, self.griddim, self.blockdim,\n\u001b[0;32m--> 770\u001b[0;31m                                     self.stream, self.sharedmem)\n\u001b[0m\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, args, griddim, blockdim, stream, sharedmem)\u001b[0m\n\u001b[1;32m    860\u001b[0m             [self.typingctx.resolve_argument_type(a) for a in args])\n\u001b[1;32m    861\u001b[0m         \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m         \u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgriddim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblockdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharedmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mspecialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self, args, griddim, blockdim, stream, sharedmem)\u001b[0m\n\u001b[1;32m    650\u001b[0m                                    sharedmem=sharedmem)\n\u001b[1;32m    651\u001b[0m         \u001b[0;31m# Invoke kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m         \u001b[0mcu_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkernelargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   2003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2004\u001b[0m         launch_kernel(self.handle, self.griddim, self.blockdim,\n\u001b[0;32m-> 2005\u001b[0;31m                       self.sharedmem, streamhandle, args)\n\u001b[0m\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36mlaunch_kernel\u001b[0;34m(cufunc_handle, griddim, blockdim, sharedmem, hstream, args)\u001b[0m\n\u001b[1;32m   2047\u001b[0m                           \u001b[0mhstream\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2048\u001b[0m                           \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2049\u001b[0;31m                           None)\n\u001b[0m\u001b[1;32m   2050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36msafe_cuda_api_call\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'call driver api: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msafe_cuda_api_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36m_check_error\u001b[0;34m(self, fname, retcode)\u001b[0m\n\u001b[1;32m    335\u001b[0m                     \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_getpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCudaDriverError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CUDA initialized before forking\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCudaAPIError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCudaAPIError\u001b[0m: [1] Call to cuLaunchKernel results in CUDA_ERROR_INVALID_VALUE"
          ]
        }
      ]
    }
  ]
}